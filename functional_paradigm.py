"""
● Контекст
Есть такая операция в статистике - “нормализация”. Это операция принимающая на вход вектор и
возвращающая другой вектор. Смысл этой операции в том, чтобы данные из разных шкал загнать в
единый диапазон, как правило - от 0 до 1, тогда с данными становится проще работать.
● Ваша задача
Реализовать с использованием функциональной парадигмы процедуру normalization, которая выполняет
нормализацию полученного массива по приведенной формуле нормализованного значения элемента, где
○ x_norm - нормализованное значение элемента
○ x - исходное значение элемента
○ x_max, x_min - максимальное и минимальное значение в массиве
"""

# def normalize(data):
#     # x_norm = (x- x_min)/(x_max-x_min)
#     x_max = max(data)
#     x_min = min(data)
#
#     def normalize_element(x):
#         return (x-x_min)/(x_max-x_min)
#
#     return list(map(normalize_element, data))
#
#
# data = [i for i in range(50, 150)]
# print(data)
# print(normalize(data))

"""
● Контекст
Предположим, что есть какой-то массив содержащий данные о разных людях и их возрасте и вас
попросили ответить на следующий вопрос: “сколько в массиве людей возраста > 30?”. Для этого, вы
хотите написать программу для фильтрации наблюдений по возрастному признаку.
● Ваша задача
Написать скрипт принимающий на вход массив с данными о людях и число - возраст, а возвращающий
число - количество людей старше указанного возраста.
"""

# people = [{'name': 'Elizaveta', 'age': 25},
#           {'name': 'Vasily', 'age': 30},
#           {'name': 'Sergey', 'age': 35},
#           {'name': 'Ivan', 'age': 40},]
#
# def filter_by_age(people: list, min_age: int) -> list:
#     return list(filter(lambda pers: min_age <= pers['age'], people))
#
# age = 30
# filtered_people = filter_by_age(people, age)
# print(filtered_people)
# print(len(filtered_people))

"""
● Контекст
Важнейшая задача в анализе данных - поиск дубликатов. Дубликат - это наблюдение, встречающееся в
данных больше одного раза. Такие наблюдения не просто не улучшают результат анализа или
полученных моделей, но и замедляют весь процесс в целом, поэтому аналитики и разработчики
предпочитают избавляться от них перед тем как приступить к анализу.
● Ваша задача
Реализовать с использованием функциональной парадигмы процедуру для поиска дубликатов. На вход
подается массив, где могут присутствовать дубликаты (а могут и не присутствовать). При применении к
массиву, дубликаты должны быть выведены на экран в виде списка.
"""
# data = [1,1,2,3,4,5,6,7,8,7,4,4,0]
# def  find_dublicates(numbers: list):
#     unique_numbers = set()
#     return list(filter(lambda x: x in unique_numbers or unique_numbers.add(x), numbers))
#
# print(find_dublicates(data))

"""
● Контекст
Корреляция - статистическая мера, используемая для оценки
связи между двумя случайными величинами.
● Ваша задача
Написать скрипт для расчета корреляции Пирсона между
двумя случайными величинами (двумя массивами). Можете
использовать любую парадигму, но рекомендую использовать
функциональную, т.к. в этом примере она значительно
упростит вам жизнь.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

data = {
    'Region': [1, 2, 3, 4],
    'Sales': [200, 150, 300, 250],
    'Advertising': [50, 40, 70, 60]
}

df = pd.DataFrame(data)
print(f"{df}\n")

correlation = df['Sales'].corr(df['Advertising'])
print(f'Корреляция между продажами и рекламой: {correlation}\n')

correlation_matrix = df.corr()
print(correlation_matrix)

sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Корреляционная матрица')
plt.show()